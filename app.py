# -*- coding: utf-8 -*-
"""Dementia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10X65e1dl6zflLhxL9PsFPvYt3ynYdmZs

## Importing
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
# from google.colab import files
import io
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
import pickle as pickle
import joblib 

"""##Loading datasets"""

# uploaded = files.upload()
# https://github.com/NizarIslah/dementia-prediction

data = pd.read_csv(r'C:\Users\Moha\Desktop\the_project\dementia-prediction-ui\Flask-api\dementia_dataset.csv')

data.head()
# data = pd.read_csv(io.BytesIO(uploaded['dementia_dataset.csv']))
# print(data.head(1000))  # Print the first few rows
# print(data.columns)  # Print the column names to verify

# Remove Converted
#data = data[data.Group != 'Converted']

# Separate features and target variable
X = data.drop(columns=['Subject ID', 'MRI ID', 'Group', 'Visit'])
y = data['Group']

# Convert categorical variables into numerical format
X = pd.get_dummies(X)

# Convert categorical variables into numerical format
X = pd.get_dummies(X)

# Missing Value Ratio
missing_ratio = X.isnull().mean()
print(missing_ratio)

# Handle missing values
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)

# Group ratio for
group_ratio = data.groupby('Group').size() / len(data)
print(group_ratio)

# len
print(len(data))

"""## Spliting the data into (Trainig and Testing)"""

# Split the data into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)

print(f'X: {X.shape}')
print(f'X_train: {X_train.shape}')
print(f'y_train: {y_train.shape}')
print(f'X_test: {X_test.shape}')
print(f'y_test: {y_test.shape}')

y_train.value_counts() / len(y_train)

"""## Feature Selection"""

# Example feature names corresponding to the features used in my model
feature_names = ['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay',
                 'M/F', 'Hand', 'Age', 'EDUC', 'SES', 'MMSE', 'CDR']

# Import necessary library
from sklearn.ensemble import RandomForestClassifier

# Initialize and train the Random Forest model (replace with my actual training data and parameters)
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)  # Assuming X_train and y_train are your training data

# Create a Series with feature importances and feature names as the index
feature_importance = pd.Series(rf_model.feature_importances_, index=feature_names)

# Plot the feature importances
feature_importance.plot(kind='barh')
plt.title('Feature Importances - Random Forest')
plt.xlabel('Importance')
plt.ylabel('Features')
plt.show()

"""## Data Pre-processing"""

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Select only numeric columns for correlation matrix
numeric_data = data.select_dtypes(include=[np.number])

# Calculate the correlation matrix
corr_matrix = numeric_data.corr()

# Create a heatmap to visualize the correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

"""##Training and Testing the Data"""

# Train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict on the testing set with Random Forest
y_pred_rf = rf_model.predict(X_test)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred_rf)

# Evaluate the Random Forest model
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy:", accuracy_rf)
report_rf = classification_report(y_test, y_pred_rf)
print("Random Forest Classification Report:\n", report_rf)

# https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea
# Assuming y_test and y_pred_rf are defined
cm = confusion_matrix(y_test, y_pred_rf)  # Get the confusion matrix

# Define group names
group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos', 'Extra1', 'Extra2', 'Extra3', 'Extra4', 'Extra5'] # Adjust this based on your confusion matrix size

# Count of each group in the confusion matrix
group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]

# Percentage of each group in the confusion matrix
group_percentages = ["{0:.2%}".format(value) for value in cm.flatten() / np.sum(cm)]

# Combine the labels with counts and percentages
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]

# Calculate the correct shape for the labels array
matrix_shape = cm.shape
# Ensure the 'labels' array has the same number of elements as the confusion matrix
labels = np.asarray(labels).reshape(matrix_shape[0], matrix_shape[1])  # Reshape to match confusion matrix

# Plot the heatmap with custom x and y labels
sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels=['Converted', 'Demented', 'NonDemented'], yticklabels=['Converted', 'Demented', 'NonDemented'])
plt.title('Confusion Matrix - Random Forest')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

# Create a pipeline that scales the data before applying the Logistic Regression
scaler = StandardScaler()
model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)

# Combine scaling and model into a pipeline
pipeline = make_pipeline(scaler, model)

# Train the pipeline
pipeline.fit(X_train, y_train)

# Predict on the testing set using the pipeline
y_pred_log_reg = pipeline.predict(X_test)

# Evaluate the Logistic Regression model
accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
print("Logistic Regression Accuracy:", accuracy_log_reg)
report_log_reg = classification_report(y_test, y_pred_log_reg)
print("Logistic Regression Classification Report:\n", report_log_reg)

# https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea
# Assuming y_test and y_pred_rf are defined
cm = confusion_matrix(y_test, y_pred_rf)  # Get the confusion matrix

# Define group names
group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos', 'Extra1', 'Extra2', 'Extra3', 'Extra4', 'Extra5'] # Adjust this based on your confusion matrix size

# Count of each group in the confusion matrix
group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]

# Percentage of each group in the confusion matrix
group_percentages = ["{0:.2%}".format(value) for value in cm.flatten() / np.sum(cm)]

# Combine the labels with counts and percentages
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]

# Calculate the correct shape for the labels array
matrix_shape = cm.shape
# Ensure the 'labels' array has the same number of elements as the confusion matrix
labels = np.asarray(labels).reshape(matrix_shape[0], matrix_shape[1])  # Reshape to match confusion matrix

# Plot the heatmap with custom x and y labels
sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels=['Converted', 'Demented', 'NonDemented'], yticklabels=['Converted', 'Demented', 'NonDemented'])
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

# # https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea
# group_names = ['True Neg','False Pos','False Neg','True Pos', 'Extra1','Extra2', 'Extra3', 'Extra4', 'Extra5'] # Add more labels to match confusion matrix size
# group_counts = ["{0:0.0f}".format(value) for value in confusion_matrix(y_test, y_pred_rf).flatten()]
# group_percentages = ["{0:.2%}".format(value) for value in
#                      confusion_matrix(y_test, y_pred_rf).flatten()/np.sum(confusion_matrix(y_test, y_pred_rf))]
# labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
#           zip(group_names,group_counts,group_percentages)]

# # Calculate the correct shape for the labels array
# matrix_shape = confusion_matrix(y_test, y_pred_rf).shape
# # Ensure the 'labels' array has the same number of elements as the confusion matrix
# labels = np.asarray(labels).reshape(matrix_shape[0], matrix_shape[1]) # Remove the extra comma to avoid creating a tuple

# sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=labels, fmt='', cmap='Blues') # Pass the NumPy array directly
# plt.title('Confusion Matrix - Logistic Regression')
# plt.xlabel('Predicted')
# plt.show()

# # Create the confusion matrix using only the labels "Demented" and "Non-Demented"
# cm_log_reg = confusion_matrix(y_test, y_pred_log_reg, labels=["Demented", "Non-Demented"])

# # Plotting the confusion matrix
# plt.figure(figsize=(8, 6))
# sns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues', xticklabels=["Demented", "Non-Demented"], yticklabels=["Demented", "Non-Demented"])
# plt.title('Confusion Matrix - Logistic Regression')
# plt.xlabel('Predicted')
# plt.show()

# Train the Support Vector Machine model
svm_model = SVC(random_state=42)
svm_model.fit(X_train, y_train)

# Predict on the testing set with SVM
y_pred_svm = svm_model.predict(X_test)

# Evaluate the SVM model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print("SVM Accuracy:", accuracy_svm)
report_svm = classification_report(y_test, y_pred_svm)
print("SVM Classification Report:\n", report_svm)

# https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea
# Assuming y_test and y_pred_rf are defined
cm = confusion_matrix(y_test, y_pred_rf)  # Get the confusion matrix

# Define group names
group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos', 'Extra1', 'Extra2', 'Extra3', 'Extra4', 'Extra5'] # Adjust this based on your confusion matrix size

# Count of each group in the confusion matrix
group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]

# Percentage of each group in the confusion matrix
group_percentages = ["{0:.2%}".format(value) for value in cm.flatten() / np.sum(cm)]

# Combine the labels with counts and percentages
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]

# Calculate the correct shape for the labels array
matrix_shape = cm.shape
# Ensure the 'labels' array has the same number of elements as the confusion matrix
labels = np.asarray(labels).reshape(matrix_shape[0], matrix_shape[1])  # Reshape to match confusion matrix

# Plot the heatmap with custom x and y labels
sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels=['Converted', 'Demented', 'NonDemented'], yticklabels=['Converted', 'Demented', 'NonDemented'])
plt.title('Confusion Matrix - Support Vector Machine')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

# Comparing the models
models = ['Random Forest', 'Logistic Regression', 'SVM']
accuracies = [accuracy_rf, accuracy_log_reg, accuracy_svm]

plt.figure(figsize=(10, 5))
sns.barplot(x=models, y=accuracies)
plt.title('Model Comparison')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.show()
joblib.dump(model, 'random_forest_model.joblib')
# Initialize and train the Logistic Regression model
log_reg_model = LogisticRegression(random_state=42) # Or any other parameters you need
log_reg_model.fit(X_train, y_train)
 
# Now perform K Fold Cross Validation for Logistic Regression
log_reg_cv_scores = cross_val_score(log_reg_model, X_train, y_train, cv=10)

# Print the cross-validation scores for Random Forest
rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=10)
print("Random Forest Cross Validation Scores:", rf_cv_scores)
print("Random Forest Mean CV Accuracy:", rf_cv_scores.mean())
print("Random Forest Std CV Accuracy:", rf_cv_scores.std())

# Print the cross-validation scores for SVM
svm_cv_scores = cross_val_score(svm_model, X_train, y_train, cv=10)  # Calculate CV scores

print("SVM Cross Validation Scores:", svm_cv_scores)
print("SVM Mean CV Accuracy:", svm_cv_scores.mean())
print("SVM Std CV Accuracy:", svm_cv_scores.std())
# Print the cross-validation scores   for Logistic Regression
print("Logistic Regression Cross Validation Scores:", log_reg_cv_scores)
print("Logistic Regression Mean CV Accuracy:", log_reg_cv_scores.mean())
print("Logistic Regression Std CV Accuracy:", log_reg_cv_scores.std())

# Calculate average accuracy for each model
avg_rf_accuracy = rf_cv_scores.mean()
avg_svm_accuracy = svm_cv_scores.mean()
avg_log_reg_accuracy = log_reg_cv_scores.mean()

# Print average accuracy for each model
print(f"Avg accuracy Random Forest: {avg_rf_accuracy}")
print(f"Avg accuracy SVM: {avg_svm_accuracy}")
print(f"Avg accuracy Logistic Regression: {avg_log_reg_accuracy}")



"""**Subject ID**: Unique ID for each study participant.
**MRI ID:** Unique ID for the MRI scan of a subject.
**Group:** Classification of the subject (e.g., control, Alzheimer's).
**Visit:** Specific time point of data collection.
**MR Delay**: Time between baseline assessment and MRI scan.
**M/F:** Gender of the subject (Male/Female).
**Hand:** Dominant hand (right, left, ambidextrous).
**Age:** Subject's age at the time of the study.
**EDUC:**Years of formal education completed.
**SES:** bold text Socioeconomic status (income, education, occupation).
**MMSE:** Cognitive function score (Mini-Mental State Examination).
**CDR:** Severity of dementia symptoms (Clinical Dementia Rating).
**eTIV:** Estimated total intracranial volume.
**nWBV:** Normalized brain volume.
**ASF:** Brain scaling factor.





---


"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'Data' is your DataFrame
# Replace 'Age', 'EDUC', etc. with the actual column names you want to analyze
variables = ['Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']

# Option 1: Using Pandas scatter_matrix
pd.plotting.scatter_matrix(data[variables], alpha=0.5, figsize=(10, 10), diagonal='hist')
plt.suptitle("Correlation between Variables", size=16)
plt.show()

# Option 2: Using Seaborn pairplot
sns.pairplot(data[variables], diag_kind='kde')  # Use 'hist' for histograms on the diagonal
plt.suptitle("Correlation between Variables", size=16)
plt.show()

# Saving the models

# Train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Save the Random Forest model to a file using pickle
with open('random_forest_model.pkl', 'wb') as rf_file:
    pickle.dump(rf_model, rf_file)

# Alternatively, use joblib to save
# joblib.dump(rf_model, 'random_forest_model.pkl')
from sklearn.preprocessing import StandardScaler
import pickle

# Assuming X_train is your training data
scaler = StandardScaler()

# Fit the scaler
scaler.fit(X_train)

# Save the scaler to a file
with open('scaler.pkl', 'wb') as scaler_file:
    pickle.dump(scaler, scaler_file)
